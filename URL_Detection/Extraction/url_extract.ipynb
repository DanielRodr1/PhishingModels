{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T05:17:19.627717Z",
     "start_time": "2025-06-11T05:17:19.623999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from urllib.parse import urlparse\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import re\n",
    "import whois\n",
    "import time\n",
    "import requests\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import entropy\n",
    "from bs4 import BeautifulSoup\n",
    "from itertools import groupby"
   ],
   "outputs": [],
   "execution_count": 253
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T05:17:19.668551Z",
     "start_time": "2025-06-11T05:17:19.647486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def resolver_redireccion(url):\n",
    "    try:\n",
    "        headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "        response = requests.get(url, timeout=8, allow_redirects=True, headers=headers)\n",
    "        return response.url\n",
    "    except:\n",
    "        return url\n",
    "\n",
    "def contar_digitos(texto):\n",
    "    return sum(c.isdigit() for c in texto)\n",
    "\n",
    "def obtener_tld(subdominio):\n",
    "    return subdominio.split('.')[-1] if '.' in subdominio else ''\n",
    "\n",
    "def string_entropy(s):\n",
    "    prob = [s.count(c) / len(s) for c in set(s)]\n",
    "    return entropy(prob, base=2)\n",
    "\n",
    "def obtener_google_index(url):\n",
    "    try:\n",
    "        parsed = urlparse(url)\n",
    "        dominio = parsed.hostname\n",
    "        if dominio is None:\n",
    "            return 0\n",
    "        headers = {\"API-Key\": \"01969e7f-04c8-744a-8245-79c2573fe845\"}\n",
    "        params = {\"q\": f\"domain:{dominio}\", \"size\": 1}\n",
    "        response = requests.get(\"https://urlscan.io/api/v1/search/\", params=params, headers=headers, timeout=3)\n",
    "        return int(response.status_code == 200 and response.json().get(\"total\", 0) > 0)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def obtener_page_rank(dominio, api_key=\"088o008o0gsgcw8k0444k8wswo84888cc0ck8kg4\"):\n",
    "    try:\n",
    "        url = \"https://openpagerank.com/api/v1.0/getPageRank\"\n",
    "        headers = {\"API-OPR\": api_key}\n",
    "        params = {\"domains[]\": dominio}\n",
    "        response = requests.get(url, headers=headers, params=params, timeout=3)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()['response'][0].get(\"page_rank_integer\", -1)\n",
    "        return -1\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "def extraer_features(url):\n",
    "    if not url.startswith((\"http://\", \"https://\")):\n",
    "        url = \"http://\" + url\n",
    "\n",
    "    # Resolver redirecciÃ³n: muy importante para analizar la URL final real\n",
    "    url = resolver_redireccion(url)\n",
    "\n",
    "    parsed = urlparse(url)\n",
    "    hostname = parsed.hostname or ''\n",
    "    path = parsed.path or ''\n",
    "\n",
    "    features = {}\n",
    "\n",
    "    features['longest_words_raw'] = max([len(word) for word in re.split(r'\\W+', url)]) if url else 0\n",
    "    features['nb_eq'] = url.count('=')\n",
    "    features['length_hostname'] = len(hostname)\n",
    "    features['length_url'] = len(url)\n",
    "\n",
    "    try:\n",
    "        dominio_sin_www = hostname[4:] if hostname.startswith(\"www.\") else hostname\n",
    "        info = whois.whois(dominio_sin_www)\n",
    "        creation_date = info.creation_date\n",
    "        if isinstance(creation_date, list):\n",
    "            creation_date = creation_date[0]\n",
    "        features['domain_age'] = (datetime.now() - creation_date).days if isinstance(creation_date, datetime) else 0\n",
    "        features['whois_registered_domain'] = int(info.domain_name is not None)\n",
    "    except:\n",
    "        features['domain_age'] = 0\n",
    "        features['whois_registered_domain'] = 0\n",
    "\n",
    "    features['nb_slash'] = url.count('/')\n",
    "    path_words = re.split(r'\\W+', path)\n",
    "    features['longest_word_path'] = max([len(word) for word in path_words]) if path_words else 0\n",
    "    features['phish_hints'] = sum(hint in url.lower() for hint in ['secure', 'account', 'update', 'login', 'verify', 'bank', 'confirm'])\n",
    "    features['nb_dots'] = url.count('.')\n",
    "    host_words = hostname.split('.') if hostname else []\n",
    "    features['shortest_word_host'] = min([len(w) for w in host_words]) if host_words else 0\n",
    "\n",
    "    features['google_index'] = obtener_google_index(url)\n",
    "    tld = obtener_tld(hostname)\n",
    "    subdomain = hostname.split('.')[0] if hostname else ''\n",
    "    features['tld_in_subdomain'] = int(tld in subdomain) if tld else 0\n",
    "    digits_url = contar_digitos(url)\n",
    "    features['ratio_digits_url'] = digits_url / len(url) if len(url) > 0 else 0\n",
    "    features['prefix_suffix'] = int('-' in hostname)\n",
    "    features['ip'] = int(bool(re.fullmatch(r'(\\d{1,3}\\.){3}\\d{1,3}', hostname)))\n",
    "    features['nb_qm'] = url.count('?')\n",
    "    digits_host = contar_digitos(hostname)\n",
    "    features['ratio_digits_host'] = digits_host / len(hostname) if len(hostname) > 0 else 0\n",
    "    features['nb_www'] = url.lower().count('www')\n",
    "    features['page_rank'] = obtener_page_rank(hostname)\n",
    "    features['nb_semicolumn'] = url.count(';')\n",
    "\n",
    "    tlds_sospechosos = ['.zip', '.review', '.country', '.stream', '.biz', '.tk', '.ml', '.ga', '.cf']\n",
    "    features['suspecious_tld'] = int(any(tld in hostname for tld in tlds_sospechosos))\n",
    "\n",
    "    features['abnormal_subdomain'] = int(len(hostname.split('.')) > 3)\n",
    "\n",
    "    # HTML features\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    except:\n",
    "        soup = BeautifulSoup(\"\", \"html.parser\")\n",
    "\n",
    "    title = soup.title.string.strip().lower() if soup.title and soup.title.string else \"\"\n",
    "    features['domain_in_title'] = int(hostname in title)\n",
    "    features['empty_title'] = int(title == '')\n",
    "    features['domain_with_copyright'] = int('copyright' in soup.get_text().lower())\n",
    "\n",
    "    forms = soup.find_all(\"form\")\n",
    "    features['login_form'] = int(any('password' in str(f).lower() for f in forms))\n",
    "    features['submit_email'] = int(any('mailto:' in (f.get(\"action\") or '').lower() for f in forms))\n",
    "    features['sfh'] = int(any((f.get(\"action\") in ['', '#', 'about:blank']) for f in forms))\n",
    "\n",
    "    links = soup.find_all(\"a\", href=True)\n",
    "    features['nb_hyperlinks'] = len(links)\n",
    "    ext_links = [a for a in links if a['href'].startswith((\"http://\", \"https://\")) and hostname not in a['href']]\n",
    "    int_links = [a for a in links if hostname in a['href']]\n",
    "    features['ratio_extHyperlinks'] = len(ext_links) / len(links) if links else 0\n",
    "    features['ratio_intHyperlinks'] = len(int_links) / len(links) if links else 0\n",
    "    features['safe_anchor'] = sum(1 for a in links if a['href'].strip() == '#') / len(links) if links else 0\n",
    "\n",
    "    tags_with_links = soup.find_all(['script', 'meta', 'link'])\n",
    "    features['links_in_tags'] = sum('href' in tag.attrs or 'src' in tag.attrs for tag in tags_with_links)\n",
    "\n",
    "    redir_meta = soup.find_all(\"meta\", attrs={\"http-equiv\": \"refresh\"})\n",
    "    features['ratio_extRedirection'] = len(redir_meta) / (len(links) + 1)\n",
    "\n",
    "    error_links = [tag for tag in soup.find_all([\"img\", \"script\"]) if tag.get(\"src\", \"\").startswith(\"http\") and \"404\" in tag.get(\"src\", \"\")]\n",
    "    features['ratio_extErrors'] = len(error_links) / (len(links) + 1)\n",
    "\n",
    "    styles = soup.find_all(\"link\", rel=\"stylesheet\")\n",
    "    features['nb_extCSS'] = sum(1 for s in styles if s.get(\"href\") and hostname not in s['href'])\n",
    "\n",
    "    favicon = soup.find(\"link\", rel=lambda x: x and \"icon\" in x.lower())\n",
    "    favicon_href = favicon.get(\"href\") if favicon else None\n",
    "    features['external_favicon'] = int(favicon_href is not None and hostname not in favicon_href)\n",
    "\n",
    "    scripts = soup.find_all(\"script\")\n",
    "    features['popup_window_size'] = int(any(\"window.open\" in s.get_text() and (\"width=\" in s.get_text() or \"height=\" in s.get_text()) for s in scripts))\n",
    "    features['right_clic'] = int(any(\"event.button==2\" in s.get_text() or \"contextmenu\" in s.get_text() for s in scripts))\n",
    "    features['onmouseover'] = int(any(\"onmouseover\" in s.get_text().lower() for s in scripts))\n",
    "\n",
    "    features['avg_word_path'] = sum(len(w) for w in path_words) / len(path_words) if path_words else 0\n",
    "    features['avg_word_host'] = sum(len(w) for w in host_words) / len(host_words) if host_words else 0\n",
    "    features['char_repeat'] = max((len(list(g)) for _, g in groupby(url)), default=0)\n",
    "\n",
    "    features['iframe'] = int(bool(soup.find(\"iframe\")))\n",
    "\n",
    "    features['brand_in_subdomain'] = int(any(brand in subdomain for brand in ['paypal', 'bank', 'login', 'secure']))\n",
    "    features['brand_in_path'] = int(any(brand in path for brand in ['paypal', 'bank', 'login', 'secure']))\n",
    "    features['domain_in_brand'] = int(hostname in path)\n",
    "\n",
    "    try:\n",
    "        alexa_response = requests.get(f\"https://data.alexa.com/data?cli=10&url={hostname}\", timeout=3)\n",
    "        features['web_traffic'] = int(\"REACH\" in alexa_response.text)\n",
    "    except:\n",
    "        features['web_traffic'] = 0\n",
    "\n",
    "    return features"
   ],
   "outputs": [],
   "execution_count": 254
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T05:17:19.676462Z",
     "start_time": "2025-06-11T05:17:19.672549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------- Cargar CSV --------\n",
    "df_urls = pd.read_csv(\"Data/data_final.csv\")  # Reemplaza con tu ruta"
   ],
   "outputs": [],
   "execution_count": 255
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T05:17:20.633732Z",
     "start_time": "2025-06-11T05:17:19.687829Z"
    }
   },
   "cell_type": "code",
   "source": "print(resolver_redireccion(\"https://www.youtube.com/watch?v=abc123\"))",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.youtube.com/watch?v=abc123\n"
     ]
    }
   ],
   "execution_count": 256
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T05:17:33.627793Z",
     "start_time": "2025-06-11T05:17:20.707851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------- Aplicar extracciÃ³n --------\n",
    "tqdm.pandas()\n",
    "features_list = df_urls[\"URL\"].progress_apply(extraer_features)\n",
    "df_features = pd.DataFrame(features_list.tolist())"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 1/1 [00:12<00:00, 12.91s/it]\n"
     ]
    }
   ],
   "execution_count": 257
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T05:17:33.645848Z",
     "start_time": "2025-06-11T05:17:33.640811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#  -------- Unir todo --------\n",
    "df_features['URL'] = df_urls['URL']\n",
    "if 'Label' in df_urls.columns:\n",
    "    df_features['Label'] = df_urls['Label']"
   ],
   "outputs": [],
   "execution_count": 258
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T05:17:33.664335Z",
     "start_time": "2025-06-11T05:17:33.657196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ð Reordenar columnas segÃºn orden original de extracciÃ³n\n",
    "# orden_columnas = [\n",
    "#     'page_rank','domain_age','google_index', 'shortest_word_host', 'nb_eq', 'ratio_digits_host',\n",
    "#     'nb_slash', 'phish_hints', 'prefix_suffix', 'nb_qm', 'longest_words_raw',\n",
    "#     'tld_in_subdomain', 'nb_dots', 'length_url', 'length_hostname', 'ratio_digits_url',\n",
    "#     'nb_www', 'ip', 'longest_word_path', 'URL', 'Label',\n",
    "# ]\n",
    "\n",
    "# orden_columnas = [\n",
    "#     'page_rank','domain_age','google_index','tld_in_subdomain','longest_words_raw','nb_slash','prefix_suffix','length_url','ratio_digits_url','ratio_digits_host','longest_word_path','nb_eq','phish_hints','nb_www','shortest_word_host','ip','length_hostname','nb_qm','nb_dots','URL', 'Label'\n",
    "# ]\n",
    "\n",
    "# original_features = ['iframe','domain_age','longest_words_raw','nb_hyperlinks','links_in_tags','tld_in_subdomain','ratio_digits_url','ratio_extRedirection','char_repeat','nb_dots','ratio_extErrors','ratio_extHyperlinks','nb_eq','length_url','google_index','ip','domain_in_title','ratio_digits_host','phish_hints','page_rank','length_hostname','login_form','longest_word_path','avg_word_path','nb_slash','empty_title','ratio_intHyperlinks','safe_anchor','avg_word_host','web_traffic','nb_www','shortest_word_host','nb_qm','prefix_suffix','URL','Label']\n",
    "\n",
    "original_features= ['abnormal_subdomain', 'longest_word_path', 'domain_in_title', 'web_traffic', 'google_index', 'char_repeat', 'length_url', 'domain_age', 'nb_www', 'ratio_intHyperlinks', 'nb_extCSS', 'nb_eq', 'longest_words_raw', 'domain_in_brand', 'tld_in_subdomain', 'length_hostname', 'links_in_tags', 'nb_dots', 'avg_word_host', 'avg_word_path', 'domain_with_copyright', 'ratio_extErrors', 'nb_hyperlinks', 'empty_title', 'page_rank', 'phish_hints', 'login_form', 'right_clic', 'safe_anchor', 'nb_slash', 'ip', 'external_favicon', 'prefix_suffix', 'ratio_extHyperlinks', 'onmouseover', 'suspecious_tld', 'nb_qm', 'shortest_word_host', 'iframe', 'ratio_digits_url', 'ratio_digits_host', 'ratio_extRedirection','URL','Label']\n",
    "df_features = df_features[original_features]"
   ],
   "outputs": [],
   "execution_count": 259
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T05:17:33.683131Z",
     "start_time": "2025-06-11T05:17:33.676950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------- Guardar --------\n",
    "df_features.to_csv(\"Data/dataset_procesado.csv\", index=False)\n",
    "print(\"Dataset guardado como dataset_procesado.csv\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset guardado como dataset_procesado.csv\n"
     ]
    }
   ],
   "execution_count": 260
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T05:17:33.706643Z",
     "start_time": "2025-06-11T05:17:33.694541Z"
    }
   },
   "cell_type": "code",
   "source": "df_features",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   abnormal_subdomain  longest_word_path  domain_in_title  web_traffic  \\\n",
       "0                   0                  0                0            0   \n",
       "\n",
       "   google_index  char_repeat  length_url  domain_age  nb_www  \\\n",
       "0             0            2          28        1467       0   \n",
       "\n",
       "   ratio_intHyperlinks  ...  onmouseover  suspecious_tld  nb_qm  \\\n",
       "0                  0.0  ...            0               0      0   \n",
       "\n",
       "   shortest_word_host  iframe  ratio_digits_url  ratio_digits_host  \\\n",
       "0                   4       0               0.0                0.0   \n",
       "\n",
       "   ratio_extRedirection                           URL  Label  \n",
       "0                   0.0  https://sistemas.super.site/      0  \n",
       "\n",
       "[1 rows x 44 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abnormal_subdomain</th>\n",
       "      <th>longest_word_path</th>\n",
       "      <th>domain_in_title</th>\n",
       "      <th>web_traffic</th>\n",
       "      <th>google_index</th>\n",
       "      <th>char_repeat</th>\n",
       "      <th>length_url</th>\n",
       "      <th>domain_age</th>\n",
       "      <th>nb_www</th>\n",
       "      <th>ratio_intHyperlinks</th>\n",
       "      <th>...</th>\n",
       "      <th>onmouseover</th>\n",
       "      <th>suspecious_tld</th>\n",
       "      <th>nb_qm</th>\n",
       "      <th>shortest_word_host</th>\n",
       "      <th>iframe</th>\n",
       "      <th>ratio_digits_url</th>\n",
       "      <th>ratio_digits_host</th>\n",
       "      <th>ratio_extRedirection</th>\n",
       "      <th>URL</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>1467</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://sistemas.super.site/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã 44 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 261
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
