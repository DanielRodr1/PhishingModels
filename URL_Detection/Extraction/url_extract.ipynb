{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T15:36:49.494323Z",
     "start_time": "2025-06-05T15:36:49.489021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from urllib.parse import urlparse\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import re\n",
    "import whois\n",
    "import time\n",
    "import requests\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import entropy\n",
    "from bs4 import BeautifulSoup\n",
    "from itertools import groupby"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T15:36:49.531615Z",
     "start_time": "2025-06-05T15:36:49.513615Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def contar_digitos(texto):\n",
    "    return sum(c.isdigit() for c in texto)\n",
    "\n",
    "def obtener_tld(subdominio):\n",
    "    return subdominio.split('.')[-1] if '.' in subdominio else ''\n",
    "\n",
    "def string_entropy(s):\n",
    "    prob = [s.count(c) / len(s) for c in set(s)]\n",
    "    return entropy(prob, base=2)\n",
    "\n",
    "def obtener_google_index(url):\n",
    "    try:\n",
    "        parsed = urlparse(url)\n",
    "        dominio = parsed.hostname\n",
    "        if dominio is None:\n",
    "            return 0\n",
    "        headers = {\"API-Key\": \"01969e7f-04c8-744a-8245-79c2573fe845\"}\n",
    "        params = {\"q\": f\"domain:{dominio}\", \"size\": 1}\n",
    "        response = requests.get(\"https://urlscan.io/api/v1/search/\", params=params, headers=headers, timeout=3)\n",
    "        return int(response.status_code == 200 and response.json().get(\"total\", 0) > 0)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def obtener_page_rank(dominio, api_key=\"088o008o0gsgcw8k0444k8wswo84888cc0ck8kg4\"):\n",
    "    try:\n",
    "        url = \"https://openpagerank.com/api/v1.0/getPageRank\"\n",
    "        headers = {\"API-OPR\": api_key}\n",
    "        params = {\"domains[]\": dominio}\n",
    "        response = requests.get(url, headers=headers, params=params, timeout=3)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()['response'][0].get(\"page_rank_integer\", -1)\n",
    "        return -1\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "def extraer_features(url):\n",
    "    if not url.startswith((\"http://\", \"https://\")):\n",
    "        url = \"http://\" + url\n",
    "\n",
    "    parsed = urlparse(url)\n",
    "    hostname = parsed.hostname or ''\n",
    "    path = parsed.path or ''\n",
    "\n",
    "    features = {}\n",
    "    features['longest_words_raw'] = max([len(word) for word in re.split(r'\\W+', url)]) if url else 0\n",
    "    features['nb_eq'] = url.count('=')\n",
    "    features['length_hostname'] = len(hostname)\n",
    "    features['length_url'] = len(url)\n",
    "\n",
    "    try:\n",
    "        dominio_sin_www = hostname[4:] if hostname.startswith(\"www.\") else hostname\n",
    "        info = whois.whois(dominio_sin_www)\n",
    "        creation_date = info.creation_date\n",
    "        if isinstance(creation_date, list):\n",
    "            creation_date = creation_date[0]\n",
    "        features['domain_age'] = (datetime.now() - creation_date).days if isinstance(creation_date, datetime) else 0\n",
    "    except:\n",
    "        features['domain_age'] = 0\n",
    "\n",
    "    features['nb_slash'] = url.count('/')\n",
    "    path_words = re.split(r'\\W+', path)\n",
    "    features['longest_word_path'] = max([len(word) for word in path_words]) if path_words else 0\n",
    "    features['phish_hints'] = sum(hint in url.lower() for hint in ['secure', 'account', 'update', 'login', 'verify', 'bank', 'confirm'])\n",
    "    features['nb_dots'] = url.count('.')\n",
    "    host_words = hostname.split('.') if hostname else []\n",
    "    features['shortest_word_host'] = min([len(w) for w in host_words]) if host_words else 0\n",
    "\n",
    "    features['google_index'] = obtener_google_index(url)\n",
    "    tld = obtener_tld(hostname)\n",
    "    subdomain = hostname.split('.')[0] if hostname else ''\n",
    "    features['tld_in_subdomain'] = int(tld in subdomain) if tld else 0\n",
    "    digits_url = contar_digitos(url)\n",
    "    features['ratio_digits_url'] = digits_url / len(url) if len(url) > 0 else 0\n",
    "    features['prefix_suffix'] = int('-' in hostname)\n",
    "    features['ip'] = int(bool(re.fullmatch(r'(\\d{1,3}\\.){3}\\d{1,3}', hostname)))\n",
    "    features['nb_qm'] = url.count('?')\n",
    "    digits_host = contar_digitos(hostname)\n",
    "    features['ratio_digits_host'] = digits_host / len(hostname) if len(hostname) > 0 else 0\n",
    "    features['nb_www'] = url.lower().count('www')\n",
    "    features['page_rank'] = obtener_page_rank(hostname)\n",
    "\n",
    "    # HTML features\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    except:\n",
    "        soup = BeautifulSoup(\"\", \"html.parser\")\n",
    "\n",
    "    title = soup.title.string.strip().lower() if soup.title and soup.title.string else \"\"\n",
    "    features['domain_in_title'] = int(hostname in title)\n",
    "\n",
    "    links = soup.find_all(\"a\", href=True)\n",
    "    features['nb_hyperlinks'] = len(links)\n",
    "\n",
    "    ext_links = [a for a in links if a['href'].startswith((\"http://\", \"https://\")) and hostname not in a['href']]\n",
    "    features['ratio_extHyperlinks'] = len(ext_links) / len(links) if links else 0\n",
    "    features['safe_anchor'] = sum(1 for a in links if a['href'].strip() == '#') / len(links) if links else 0\n",
    "\n",
    "    tags_with_links = soup.find_all(['script', 'meta', 'link'])\n",
    "    features['links_in_tags'] = sum('href' in tag.attrs or 'src' in tag.attrs for tag in tags_with_links)\n",
    "\n",
    "    redir_meta = soup.find_all(\"meta\", attrs={\"http-equiv\": \"refresh\"})\n",
    "    features['ratio_extRedirection'] = len(redir_meta) / (len(links) + 1)\n",
    "\n",
    "    error_links = [tag for tag in soup.find_all([\"img\", \"script\"]) if tag.get(\"src\", \"\").startswith(\"http\") and \"404\" in tag.get(\"src\", \"\")]\n",
    "    features['ratio_extErrors'] = len(error_links) / (len(links) + 1)\n",
    "\n",
    "    features['avg_word_path'] = sum(len(w) for w in path_words) / len(path_words) if path_words else 0\n",
    "    features['avg_word_host'] = sum(len(w) for w in host_words) / len(host_words) if host_words else 0\n",
    "    features['char_repeat'] = max((len(list(g)) for _, g in groupby(url)), default=0)\n",
    "\n",
    "    features['iframe'] = int(bool(soup.find(\"iframe\")))\n",
    "    forms = soup.find_all(\"form\")\n",
    "    features['login_form'] = int(any('password' in str(f).lower() for f in forms))\n",
    "\n",
    "    # empty_title\n",
    "    features['empty_title'] = int(title == '')\n",
    "\n",
    "    # ratio_intHyperlinks: enlaces internos\n",
    "    int_links = [a for a in links if hostname in a['href']]\n",
    "    features['ratio_intHyperlinks'] = len(int_links) / len(links) if links else 0\n",
    "\n",
    "    # web_traffic: valor simulado o real\n",
    "    try:\n",
    "        alexa_response = requests.get(f\"https://data.alexa.com/data?cli=10&url={hostname}\", timeout=3)\n",
    "        features['web_traffic'] = int(\"REACH\" in alexa_response.text)\n",
    "    except:\n",
    "        features['web_traffic'] = 0\n",
    "\n",
    "    return features"
   ],
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T15:36:49.541256Z",
     "start_time": "2025-06-05T15:36:49.535617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------- Cargar CSV --------\n",
    "df_urls = pd.read_csv(\"Data/data_final.csv\")  # Reemplaza con tu ruta"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T15:36:52.843432Z",
     "start_time": "2025-06-05T15:36:49.552673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------- Aplicar extracci√≥n --------\n",
    "tqdm.pandas()\n",
    "features_list = df_urls[\"URL\"].progress_apply(extraer_features)\n",
    "df_features = pd.DataFrame(features_list.tolist())"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:03<00:00,  3.29s/it]\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T15:36:52.859498Z",
     "start_time": "2025-06-05T15:36:52.855564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#  -------- Unir todo --------\n",
    "df_features['URL'] = df_urls['URL']\n",
    "if 'Label' in df_urls.columns:\n",
    "    df_features['Label'] = df_urls['Label']"
   ],
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T15:36:52.877242Z",
     "start_time": "2025-06-05T15:36:52.871464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# üîÉ Reordenar columnas seg√∫n orden original de extracci√≥n\n",
    "# orden_columnas = [\n",
    "#     'page_rank','domain_age','google_index', 'shortest_word_host', 'nb_eq', 'ratio_digits_host',\n",
    "#     'nb_slash', 'phish_hints', 'prefix_suffix', 'nb_qm', 'longest_words_raw',\n",
    "#     'tld_in_subdomain', 'nb_dots', 'length_url', 'length_hostname', 'ratio_digits_url',\n",
    "#     'nb_www', 'ip', 'longest_word_path', 'URL', 'Label',\n",
    "# ]\n",
    "\n",
    "# orden_columnas = [\n",
    "#     'page_rank','domain_age','google_index','tld_in_subdomain','longest_words_raw','nb_slash','prefix_suffix','length_url','ratio_digits_url','ratio_digits_host','longest_word_path','nb_eq','phish_hints','nb_www','shortest_word_host','ip','length_hostname','nb_qm','nb_dots','URL', 'Label'\n",
    "# ]\n",
    "\n",
    "# original_features = ['iframe','domain_age','longest_words_raw','nb_hyperlinks','links_in_tags','tld_in_subdomain','ratio_digits_url','ratio_extRedirection','char_repeat','nb_dots','ratio_extErrors','ratio_extHyperlinks','nb_eq','length_url','google_index','ip','domain_in_title','ratio_digits_host','phish_hints','page_rank','length_hostname','login_form','longest_word_path','avg_word_path','nb_slash','empty_title','ratio_intHyperlinks','safe_anchor','avg_word_host','web_traffic','nb_www','shortest_word_host','nb_qm','prefix_suffix','URL','Label']\n",
    "\n",
    "original_features= ['nb_qm','longest_word_path','nb_slash','nb_dots','length_hostname','ratio_intHyperlinks','domain_age','login_form','ip','links_in_tags','ratio_extHyperlinks','ratio_extRedirection','ratio_digits_host','nb_hyperlinks','prefix_suffix','empty_title','nb_www','iframe','domain_in_title','nb_eq','web_traffic','phish_hints','shortest_word_host','google_index','longest_words_raw','avg_word_path','ratio_extErrors','avg_word_host','length_url','page_rank','ratio_digits_url','char_repeat','tld_in_subdomain','safe_anchor','URL','Label']\n",
    "df_features = df_features[original_features]"
   ],
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T15:36:52.897461Z",
     "start_time": "2025-06-05T15:36:52.892374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------- Guardar --------\n",
    "df_features.to_csv(\"Data/dataset_procesado.csv\", index=False)\n",
    "print(\"Dataset guardado como dataset_procesado.csv\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset guardado como dataset_procesado.csv\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T15:36:52.939302Z",
     "start_time": "2025-06-05T15:36:52.923711Z"
    }
   },
   "cell_type": "code",
   "source": "df_features",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   nb_qm  longest_word_path  nb_slash  nb_dots  length_hostname  \\\n",
       "0      0                  5         3        1               12   \n",
       "\n",
       "   ratio_intHyperlinks  domain_age  login_form  ip  links_in_tags  ...  \\\n",
       "0                    0        2438           0   0              0  ...   \n",
       "\n",
       "   ratio_extErrors  avg_word_host  length_url  page_rank  ratio_digits_url  \\\n",
       "0              0.0            5.5          26          5               0.0   \n",
       "\n",
       "   char_repeat  tld_in_subdomain  safe_anchor                         URL  \\\n",
       "0            2                 0            0  https://acortar.link/iBtuP   \n",
       "\n",
       "   Label  \n",
       "0      0  \n",
       "\n",
       "[1 rows x 36 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_qm</th>\n",
       "      <th>longest_word_path</th>\n",
       "      <th>nb_slash</th>\n",
       "      <th>nb_dots</th>\n",
       "      <th>length_hostname</th>\n",
       "      <th>ratio_intHyperlinks</th>\n",
       "      <th>domain_age</th>\n",
       "      <th>login_form</th>\n",
       "      <th>ip</th>\n",
       "      <th>links_in_tags</th>\n",
       "      <th>...</th>\n",
       "      <th>ratio_extErrors</th>\n",
       "      <th>avg_word_host</th>\n",
       "      <th>length_url</th>\n",
       "      <th>page_rank</th>\n",
       "      <th>ratio_digits_url</th>\n",
       "      <th>char_repeat</th>\n",
       "      <th>tld_in_subdomain</th>\n",
       "      <th>safe_anchor</th>\n",
       "      <th>URL</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2438</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://acortar.link/iBtuP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows √ó 36 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
